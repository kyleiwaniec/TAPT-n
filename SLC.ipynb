{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLC - Sentence Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chkp = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chkp, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(chkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chkp = \"roberta_propaganda_spans\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chkp, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(chkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/PTC_TAPT_n_RoBERTa were not used when initializing RobertaForSequenceClassification: ['roberta.Ngram_embeddings.LayerNorm.weight', 'roberta.encoder.Ngram_layer.0.output.dense.weight', 'lm_head.bias', 'roberta.encoder.Ngram_layer.0.output.LayerNorm.bias', 'roberta.Ngram_embeddings.LayerNorm.bias', 'roberta.Ngram_embeddings.token_type_embeddings.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.Ngram_layer.0.output.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.Ngram_layer.0.attention.self.key.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.Ngram_layer.0.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.Ngram_layer.0.output.LayerNorm.weight', 'roberta.encoder.Ngram_layer.0.attention.output.dense.bias', 'roberta.encoder.Ngram_layer.0.attention.self.query.bias', 'roberta.encoder.Ngram_layer.0.attention.self.query.weight', 'lm_head.dense.weight', 'roberta.Ngram_embeddings.word_embeddings.weight', 'roberta.encoder.Ngram_layer.0.intermediate.dense.bias', 'roberta.encoder.Ngram_layer.0.attention.self.value.weight', 'roberta.encoder.Ngram_layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.Ngram_layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.Ngram_layer.0.intermediate.dense.weight', 'roberta.encoder.Ngram_layer.0.attention.self.key.bias', 'lm_head.decoder.weight', 'roberta.encoder.Ngram_layer.0.attention.self.value.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ../models/PTC_TAPT_n_RoBERTa and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "chkp = \"../models/PTC_TAPT_n_RoBERTa\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chkp, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(chkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Kyleiwaniec--SemEval_2020_Task_11-b52b8595f0b41308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None (download: 1.71 MiB, generated: 3.91 MiB, post-processed: Unknown size, total: 5.62 MiB) to /Users/kylehamilton/.cache/huggingface/datasets/Kyleiwaniec___parquet/Kyleiwaniec--SemEval_2020_Task_11-b52b8595f0b41308/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acdabbf9cdd4a5fbce83a831d936356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1aa91aaa0a4469e81d1a0d0cec4406c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #1:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bc85460a034053b9be6e4d180688ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #0:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d823d7df0464f76a48dfd9d73a26bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #2:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/kylehamilton/.cache/huggingface/datasets/Kyleiwaniec___parquet/Kyleiwaniec--SemEval_2020_Task_11-b52b8595f0b41308/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5daf30d9264ca5931e318aea3138db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('Kyleiwaniec/SemEval_2020_Task_11', use_auth_token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c22e86334e64b25bd1bb130e4da0662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f7c91a25c64da2ab44c8bb124c26c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1763adb945e146a59b9617e5151ea56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['article_id', 'text', 'technique_classification', 'offsets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_dataset[\"validation\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ccbf6f2c4712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtiny_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtiny_eval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "tiny_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(10))\n",
    "tiny_eval_dataset = tokenized_dataset[\"validation\"].shuffle(seed=42).select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_id': 'article111111111',\n",
       " 'text': '\"The next transmission could be more pronounced or stronger,\" WHO Director-General Tedros Adhanom Ghebreyesus told reporters in Geneva, insisting that \"the issue is serious.\"',\n",
       " 'technique_classification': [0],\n",
       " 'offsets': [[1, 59]],\n",
       " 'labels': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylehamilton/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b9384ebd3240ddace217c51099ce46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "#,\"matthews_correlation\",\"f1\",\"precision\",\"recall\"\n",
    "metrics = load_metric(\"f1\",\"matthews_correlation\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return  metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(chkp, return_dict=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test\", \n",
    "    eval_steps=500, \n",
    "    no_cuda=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.hyperparameter_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khamilton/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/63 : < :, Epoch 0.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no_cuda=True\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=chkp+\"_SLC/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=48,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    no_cuda=True\n",
    ")\n",
    "\n",
    "# compute_metrics=compute_metrics,\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Kyleiwaniec--SemEval_2020_Task_11-b52b8595f0b41308\n",
      "Found cached dataset parquet (/Users/kylehamilton/.cache/huggingface/datasets/Kyleiwaniec___parquet/Kyleiwaniec--SemEval_2020_Task_11-b52b8595f0b41308/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2172918333634dedb9bb39247f14b5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('Kyleiwaniec/SemEval_2020_Task_11', use_auth_token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chkp = \"Kyleiwaniec/PTC_TAPT_RoBERTa_large_SLC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aef5b0c09e7473e85911bf6e8ec6ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/PTC_TAPT_n_RoBERTa_SLC\")\n",
    "classifier = pipeline(\"text-classification\", model=chkp, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_id': 'article813452859',\n",
       " 'text': 'EU Profits From Trading With UK While London Loses Money – Political Campaigner',\n",
       " 'technique_classification': [],\n",
       " 'offsets': [],\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in dataset['train']:\n",
    "    pred = classifier(i['text'])[0]['label']\n",
    "    pred = int(pred[-1])\n",
    "    y = i['labels']\n",
    "    predictions.append([pred,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16910"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4233 12060 284 333\n",
      "0.9635127143701951\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "TP, TN, FP, FN = 0,0,0,0\n",
    "for p in predictions:\n",
    "    if p[0] == p[1]: acc+=1\n",
    "    if p[0] == 1 and p[1] == 1:\n",
    "        TP+=1\n",
    "    if p[0] == 0 and p[1] == 0:\n",
    "        TN+=1\n",
    "    if p[0] == 1 and p[1] == 0:\n",
    "        FP+=1\n",
    "    if p[0] == 0 and p[1] == 1:\n",
    "        FN+=1\n",
    "    \n",
    "print(TP, TN, FP, FN) \n",
    "print(acc/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "EPS = 1e-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP/(TP+FP+EPS)\n",
    "recall = TP/(TP+FN+EPS)\n",
    "F1 = (2*precision*recall)/(precision+recall)\n",
    "MCC = (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))+EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9371264113349568 0.9270696452036794 0.9320709016844655 0.9071541738228892\n"
     ]
    }
   ],
   "source": [
    "print(precision,recall,F1,MCC)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "precision,recall,F1,MCC\n",
    "\n",
    "\n",
    "Kyleiwaniec/PTC_TAPT_RoBERTa_large_SLC (validation data)\n",
    "520 2166 281 244\n",
    "0.8364995328558081\n",
    "0.6491885143570537 0.680628272251309 0.6645367412140576 0.5567972148181395\n",
    "\n",
    "\n",
    "Kyleiwaniec/PTC_TAPT_RoBERTa_large_SLC (test data)\n",
    "610 1920 190 495\n",
    "0.7869362363919129\n",
    "0.7625 0.5520361990950227 0.6404199475065617 0.5075166072878464\n",
    "\n",
    "fine-tuned Roberta\n",
    "0.7377049180327869 0.48868778280542985 0.5879150789330431 0.45042853055771964\n",
    "\n",
    "fine-tuned distillbert\n",
    "0.750373692077728 0.45429864253393665 0.5659526493799324 0.4389217010596852\n",
    "0.7262723521320495 0.47782805429864256 0.5764192139737991 0.43542425774364657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105 0 2110 0\n",
      "0.343701399688958 1.0 0.5115740740740741 0.0\n"
     ]
    }
   ],
   "source": [
    "# All propagnda. We are going to pretend that all predictions are 1\n",
    "# This matches the baseline from the paper.\n",
    "TP, TN, FP, FN = 0,0,0,0\n",
    "for p in predictions:\n",
    "    if p[0] == 1 and p[1] == 1:\n",
    "        TP+=1\n",
    "    if p[0] == 0 and p[1] == 0:\n",
    "        FP+=1\n",
    "    if p[0] == 1 and p[1] == 0:\n",
    "        FP+=1\n",
    "    if p[0] == 0 and p[1] == 1:\n",
    "        TP+=1\n",
    "    \n",
    "print(TP, TN, FP, FN) \n",
    "precision = TP/(TP+FP+EPS)`\n",
    "recall = TP/(TP+FN+EPS)\n",
    "F1 = (2*precision*recall)/(precision+recall)\n",
    "MCC = (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))+EPS)\n",
    "print(precision,recall,F1,MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
